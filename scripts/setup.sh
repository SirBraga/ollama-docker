#!/bin/bash

# Script de setup para Ollama Docker
# Executa a configura√ß√£o inicial e baixa o modelo LLaMA

set -e

echo "üöÄ Iniciando setup do Ollama..."

# Verifica se Docker est√° instalado
if ! command -v docker &> /dev/null; then
    echo "‚ùå Docker n√£o encontrado. Instale o Docker primeiro."
    exit 1
fi

# Verifica se docker-compose est√° dispon√≠vel
if ! command -v docker compose &> /dev/null; then
    echo "‚ùå Docker Compose n√£o encontrado."
    exit 1
fi

# Detecta se h√° GPU NVIDIA dispon√≠vel
if command -v nvidia-smi &> /dev/null; then
    echo "‚úÖ GPU NVIDIA detectada. Usando configura√ß√£o com GPU."
    COMPOSE_FILE="docker-compose.yml"
else
    echo "‚ö†Ô∏è  GPU NVIDIA n√£o detectada. Usando configura√ß√£o CPU only."
    COMPOSE_FILE="docker-compose.cpu.yml"
fi

# Sobe os containers
echo "üì¶ Subindo containers..."
docker compose -f "$COMPOSE_FILE" up -d

# Aguarda o Ollama iniciar
echo "‚è≥ Aguardando Ollama iniciar..."
sleep 10

# Baixa o modelo LLaMA
echo "üì• Baixando modelo LLaMA 3.2 (3B)..."
docker exec ollama ollama pull llama3.2

echo ""
echo "‚úÖ Setup conclu√≠do!"
echo ""
echo "üìç Endpoints dispon√≠veis:"
echo "   - API Ollama: http://localhost:11434"
echo "   - Web UI: http://localhost:3000"
echo ""
echo "üí° Comandos √∫teis:"
echo "   - Listar modelos: docker exec ollama ollama list"
echo "   - Rodar modelo: docker exec -it ollama ollama run llama3.2"
echo "   - Baixar outro modelo: docker exec ollama ollama pull <modelo>"
